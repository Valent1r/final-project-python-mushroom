{
 "cells": [ 
{
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install webdriver_manager\n",
    "!pip install Image"
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Extracts information about mushrooms from the website http://www.mushroom.world. \n",
"-1.Uses the BeautifulSoup library (from bs4 import BeautifulSoup) to perform HTML analysis of web pages, and the modules requests, re, json, and urljoin to make HTTP requests, handle regular expressions, process JSON data, and manage URLs, respectively. \n",
"\n",
"-2.Scrape_mushroom_list(url) takes a URL as a parameter, retrieves the HTML content of the page, finds all links pointing to individual mushroom pages, and then uses the function scrape_mushroom(url) to extract specific information about each mushroom. \n",
"\n",
"-3.The function scrape_mushroom(url) retrieves information such as the name, labels, texts, and images for a specific mushroom from its individual page. \n",
"\n",
"-4.The script uses a dictionary (edibility_dict) to store information about the edibility of mushrooms, where 'c' stands for edible, and 'p' stands for poisonous. \n",
"\n",
"-5.The edibility information for each mushroom extracted from the web page is removed since the value is empty, and the edibility is added to the final output each extracted mushroom. \n",
"\n",
"###Script displays information about all mushrooms in an indented JSON string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
"import requests \n",
"import re \n",
"import json \n",
"from urllib.parse import urljoin \n",
"\n",
"def scrape_mushroom_list(url): \n",
    "data = requests.get(url).text \n",
    "soup = BeautifulSoup(data, 'html.parser') \n",
    "\n",
    "# Find all links to individual mushroom pages \n",
    "mushroom_links = soup.find_all('a', href=re.compile(r'/show?n=')) \n",
    "mushroom_urls = [urljoin('http://www.mushroom.world', link['href']) for link in mushroom_links] \n",
    "\n",
    "# Retrieve information for each mushroom\n",
    "mushrooms = [scrape_mushroom(link) for link in mushroom_urls] \n",
    "\n",
 "return mushrooms"
   ]
  },


{
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def scrape_mushroom(url): \n",
    "data = requests.get(url).text \n",
    "soup = BeautifulSoup(data, 'html.parser') \n",
"\n",
    "# Extract specific information for an individual mushroom \n",
    "name_content = soup.find(class_='caption').find('b').contents \n",
    "names = re.sub('[^A-Za-z0-9( ]+', '', name_content[0])).split('(')) \n",
    "names = [n.strip() for n in names] \n",
    "name1 = names[0] \n",
    "name2 = names[1] if len(names) > 1 else '' \n",
"\n",
    "labels = soup.find_all(class_='labelus') \n",
    "labels = [label.contents[0] for label in labels] \n",
"\n",
    "texts = soup.find_all(class_='textus') \n",
    "texts = [text.contents[0] for text in texts] \n",
"\n",
    "# Updated code to remove unwanted lines \n",
    "description = soup.find(class_='longtextus') \n",
    "if description: \n",
        "unwanted_links = description.find_all('a', href=True) \n",
        "for link in unwanted_links: \n",
            "link.extract()  # Remove unwanted links \n",
"\n",
        "description = description.get_text(separator=' ', strip=True) \n",
    "else: \n",
        "description = 'Description not available' \n",
"\n",
    "texts.append(description) \n",
    "assert len(labels) == len(texts) \n",
"\n",
    "images = soup.find(id='mushroom-list').find_all(class_='image') \n",
    "image_urls = [urljoin('http://www.mushroom.world', image.a['href']) for image in images] \n",
"\n",
    "mushroom = dict(name1=name1, name2=name2, images=image_urls, info=dict()) \n",
"\n",
    "for i in range(len(labels)): \n",
        "mushroom['info'][labels[i]] = texts[i] \n",
"\n",
    "return mushroom"

   ]
  },



{
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [

"if __name__ == '__main__': \n",
    "# Link to the list of all mushrooms on mushroom.world \n",
    "all_mushrooms_url = 'http://www.mushroom.world/mushrooms/namelist' \n",
"\n",
    "# Retrieve information on all mushrooms \n",
    "all_mushrooms = scrape_mushroom_list(all_mushrooms_url) \n",
"\n",
    "# Edibility dictionary \n",
    "edibility_dict = { \n",
        "# ... (your edibility dictionary remains unchanged)\n",
          "'Agaricus arvensis': 'c', \n",
  "'Agaricus augustus': 'c', \n",
  "'Agaricus campestris': 'c', \n",
  "'Agaricus sylvicola': 'c', \n",
  "'Agrocybe pediades': 'c', \n",
  "'Agrocybe praecox': 'c', \n",
  "'Albatrellus confluens': 'p', \n",
  "'Albatrellus ovinus': 'c', \n",
  "'Aleuria aurantia': 'p', \n",
  "'Amanita battarrae': 'p',\n",
  "'Amanita bisporigera': 'p',\n",
  "'Amanita cokeri': 'p',\n",
  "'Amanita fulva': 'p',\n",
  "'Amanita jacksonii': 'p',\n",
  "'Amanita muscaria': 'p',\n",
  "'Amanita pantherina': 'p',\n",
  "'Amanita phalloides': 'p',\n",
  "'Amanita porphyria': 'p',\n",
  "'Amanita regalis': 'p',\n",
  "'Amanita rubescens': 'c',\n",
  "'Amanita vaginata': 'p',\n",
  "'Amanita virosa': 'p',\n",
  "'Ampulloclitocybe clavipes': 'p',\n",
  "'Armillaria mellea': 'c',\n",
  "'Auriscalpium vulgare': 'p',\n",
  "'Bankera fuligineoalba': 'p',\n",
  "'Boletus edulis': 'c',\n",
  "'Boletus pinophilus': 'c',\n",
  "'Bondarzewia berkeleyi': 'p',\n",
  "'Bovista nigrescens': 'p',\n",
  "'Bovista plumbea': 'p',\n",
  "'Calocera viscosa': 'p',\n",
  "'Calocybe gambosa': 'p',\n",
  "'Calocybe persicolor': 'p',\n",
  "'Calvatia gigantea': 'p',\n",
  "'Cantharellula umbonata': 'p',\n",
  "'Cantharellus cibarius': 'c',\n",
  "'Chalciporus piperatus': 'p',\n",
  "'Chlorophyllum molybdites': 'p',\n",
  "'Chlorophyllum rhacodes': 'p',\n",
  "'Chroogomphus britannicus': 'p',\n",
  "'Clathrus ruber': 'p',\n",
  "'Conocybe apala': 'p',\n",
  "'Coprinellus disseminatus': 'p',\n",
  "'Coprinellus xanthothrix': 'p',\n",
  "'Coprinopsis atramentaria': 'p',\n",
  "'Coprinopsis variegata': 'p',\n",
  "'Conocybe apala': 'p',\n",
  "'Coprinopsis variegata': 'p',\n",
  "'Coprinus comatus': 'p',\n",
  "'Coprinus plicatilis': 'p',\n",
  "'Cortinarius alboviolaceus': 'p',\n",
  "'Cortinarius armillatus': 'p',\n",
  "'Cortinarius camphoratus': 'p',\n",
  "'Cortinarius caperatus': 'p',\n",
  "'Cortinarius collinitus': 'p',\n",
  "'Cortinarius croceus': 'p',\n",
  "'Cortinarius laniger': 'p',\n",
  "'Cortinarius malicorius': 'p',\n",
  "'Cortinarius mucosus': 'p',\n",
  "'Cortinarius orellanus': 'p',\n",
  "'Cortinarius rubellus': 'p',\n",
  "'Cortinarius semisanguineus': 'p',\n",
  "'Cortinarius traganus': 'p',\n",
  "'Cortinarius violaceus': 'p',\n",
  "'Craterellus tubaeformis': 'c',\n",
  "'Cystoderma amianthinum': 'p',\n",
  "'Cystodermella cinnabarina': 'p',\n",
  "'Entoloma sericeum': 'p',\n",
  "'Entoloma vernum': 'p',\n",
  "'Galerina marginata': 'p',\n",
  "'Geastrum rufescens': 'p',\n",
  "'Gomphidius glutinosus': 'p',\n",
  "'Gymnopilus picreus': 'p',\n",
  "'Gymnopus peronatus': 'p',\n",
  "'Gyromitra esculenta': 'p',\n",
  "'Gyromitra esculenta': 'p',\n",
  "'Gyromitra infula': 'p',\n",
  "'Hebeloma crustuliniforme': 'p',\n",
  "'Hebeloma mesophaeum': 'p',\n",
  "'Helvella elastica': 'p',\n",
  "'Hericium americanum': 'p',\n",
  "'Hericium cirrhatum': 'p',\n",
  "'Hericium erinaceus': 'p',\n",
  "'Hortiboletus rubellus': 'p',\n",
  "'Hydnum repandum': 'p',\n",
  "'Hydnum rufescens': 'p',\n",
  "'Hygrophoropsis aurantiaca': 'p',\n",
  "'Hygrophorus camarophyllus': 'p',\n",
  "'Hygrophorus hypothejus': 'p',\n",
  "'Hygrophorus hypothejus': 'p',\n",
  "'Hygrophorus pustulatus': 'c',\n",
  "'Hypholoma capnoides': 'p',\n",
  "'Hypholoma fasciculare': 'p',\n",
  "'Hypholoma lateritium': 'p',\n",
  "'Hypholoma lateritium': 'p',\n",
  "'Hypholoma marginatum': 'p',\n",
  "'Imleria badia': 'p',\n",
  "'Inocybe lacera': 'p',\n",
  "'Kuehneromyces lignicola': 'p',\n",
  "'Kuehneromyces mutabilis': 'p',\n",
  "'Laccaria laccata': 'p',\n",
  "'Lacrymaria lacrymabunda': 'p',\n",
  "'Lactarius camphoratus': 'p',\n",
  "'Lactarius deliciosus': 'c',\n",
  "'Lactarius deterrimus': 'p',\n",
  "'Lactarius helvus': 'p',\n",
  "'Lactarius indigo': 'p',\n",
  "'Lactarius lignyotus': 'p',\n",
  "'Lactarius mammosus': 'p',\n",
  "'Lactarius rufus': 'p',\n",
  "'Lactarius tabidus': 'p',\n",
  "'Lactarius torminosus': 'p',\n",
  "'Lactarius trivialis': 'p',\n",
  "'Lactarius turpis': 'p',\n",
  "'Lactarius volemus': 'p',\n",
  "'Lactifluus piperatus': 'p',\n",
  "'Laetiporus sulphureus': 'p',\n",
  "'Leccinum aurantiacum': 'p',\n",
  "'Leccinum scabrum': 'p',\n",
  "'Leccinum versipelle': 'p',\n",
  "'Lepiota clypeolaria': 'p',\n",
  "'Leucocoprinus birnbaumii': 'p',\n",
  "'Leucocybe connata': 'p',\n",
  "'Lycoperdon excipuliforme': 'p',\n",
  "'Lycoperdon nigrescens': 'p',\n",
  "'Lycoperdon perlatum': 'p',\n",
  "'Lycoperdon pratense': 'p',\n",
  "'Lycoperdon pyriforme': 'p',\n",
  "'Macrolepiota procera': 'p',\n",
  "'Marasmiellus perforans': 'p',\n",
  "'Marasmius oreades': 'p',\n",
  "'Melanoleuca cognata': 'p',\n",
  "'Morchella elata': 'p',\n",
  "'Morchella esculenta': 'p',\n",
  "'Mycena epipterygia': 'p',\n",
  "'Mycena galericulata': 'p',\n",
  "'Mycena laevigata': 'p',\n",
  "'Mycena pura': 'p',\n",
  "'Omphalotus illudens': 'p',\n",
  "'Omphalotus olearius': 'p',\n",
  "'Otidea onotica': 'p',\n",
  "'Panaeolus foenisecii': 'p',\n",
  "'Paxillus involutus': 'p',\n",
  "'Peziza badia': 'p',\n",
  "'Phallus impudicus': 'p',\n",
  "'Phallus rubicundus': 'p',\n",
  "'Pholiota alnicola': 'p',\n",
  "'Pholiota aurivella': 'p',\n",
  "'Pholiota limonella': 'p',\n",
  "'Pholiota squarrosa': 'p',\n",
  "'Pleurotus citrinopileatus': 'p',\n",
  "'Pleurotus ostreatus': 'c',\n",
  "'Pleurotus pulmonarius': 'c',\n",
  "'Polyporus ciliatus': 'p',\n",
  "'Polyporus squamosus': 'p',\n",
  "'Psathyrella candolleana': 'c',\n",
  "'Psathyrella microrrhiza': 'p',\n",
  "'Psathyrella sp.': 'p',\n",
  "'Psilocybe semilanceata': 'p',\n",
  "'Rickenella swartzii': 'c',\n",
  "'Rubroboletus satanas': 'p',\n",
  "'Russula acrifolia': 'p', \n",
  "'Russula adusta': 'p', \n",
  "'Russula aeruginea': 'p',\n",
  "'Russula claroflava': 'p',\n",
  "'Russula paludosa': 'c',\n",
  "'Russula velenovskyi': 'p',\n",
  "'Russula vesca': 'c',\n",
  "'Russula vinosa': 'c',\n",
  "'Russula xerampelina': 'c',\n",
  "'Sarcodon squamosus': 'p',\n",
  "'Strobilomyces strobilaceus': 'p',\n",
  "'Strobilurus esculentus': 'c',\n",
  "'Strobilurus stephanocystis': 'p',\n",
  "'Stropharia hornemannii': 'p',\n",
  "'Suillus americanus': 'c', \n",
  "'Suillus bovinus': 'c', \n",
  "'Suillus grevillei': 'p', \n",
  "'Suillus luteus': 'c', \n",
  "'Suillus variegatus': 'p', \n",
  "'Tapinella atrotomentosa': 'c', \n",
  "'Tapinella panuoides': 'p', \n",
  "'Tricholoma aestuans': 'p', \n",
  "'Tricholoma equestre': 'c', \n",
  "'Tricholoma focale': 'p', \n",
  "'Tricholoma saponaceum': 'p', \n",
  "'Tricholoma sejunctum': 'p', \n",
  "'Tricholoma stiparophyllum': 'p', \n",
  "'Tricholomopsis decora': 'p', \n",
  "'Tricholomopsis rutilans': 'p', \n",
  "'Turbinellus floccosus': 'p', \n",
  "'Tylopilus felleus': 'p', \n",
  "'Xerocomellus chrysenteron': 'c', \n",
  "'Xerocomus subtomentosus': 'c', \n",
  "'Xeromphalina campanella': 'p', \n",
  "'Tricholomopsis decora': 'p', \n",
  "'Clitocybe gibba': 'c', \n",
  "'Clitocybe nuda': 'c', \n",
  "'Clitopilus prunulus': 'c', \n",
  "'Collybia dryophila': 'c', \n",
  "'Coltricia perennis': 'p', \n",
  "'Conocybe apalas': 'p', \n",
  "'Marasmius rotula': 'p', \n",
  "'Tricholomataceae': 'c', \n",
  "'Ramaria lutea': 'p', \n",
  "'Rhizina undulata': 'p', \n",
  "'Russula decolorans': 'c', \n",
  "'Russula emetica': 'p', \n",
  "'Russula mustelina': 'c', \n",
  "'Clitocybe nebularis': 'p', \n",
    "}\n",
 "\n",
    "# Add edibility to final output \n",
    "for mushroom in all_mushrooms: \n",
        "name = mushroom['name1'] \n",
        "if name in edibility_dict: \n",
            "mushroom['comestibility'] = edibility_dict[name] \n",
        "else: \n",
            "mushroom['comestibility'] = 'Information not available' \n",
        "# Delete edibility information from web page \n",
        "if 'Edibility' in mushroom['info']: \n",
            "del mushroom['info']['Edibility'] \n",
 "\n",
    "# Display information (or save to file, etc.) \n",
    "print(json.dumps(all_mushrooms, indent=2))"
   ]
  },



{
   "cell_type": "markdown",
   "metadata": {},
   "source": [ 
    " ## Uses the Python libraries pandas and Pillow (PIL) to process data from a JSON file containing information about mushrooms. \n",
"\n",
    " ### 1.Import Libraries : \n",
"\n",
    "-import pandas as pd : Imports the pandas library and aliases it as pd. \n",
"\n",
    "-from PIL import Image: Imports the Image module from the Pillow library for working with images. \n",
"\n",
    " ### 2.File Path and Data Loading: \n",
"\n",
    "-file_path = 'champiURL.json': Specifies the file path for the JSON file containing mushroom information. \n",
"\n",
    "-df = pd.read_json(file_path): Reads the JSON file into a pandas DataFrame. \n",
"\n",
    " ### 3.Data Processing: \n",
"\n",
    "-df = df.explode('images', ignore_index=True): Explodes the 'images' column, which likely contains lists of image URLs, into separate rows while ignoring the index. This is often done to handle nested lists in DataFrames. \n",
"\n",
    "-df = df.drop(columns=['info']): Drops the 'info' column from the DataFrame. \n",
"\n",
    " ### 4.Mapping Comestibility: \n",
"\n",
    "-Dico = {'c': 1, 'p': 0}: Creates a dictionary mapping comestibility codes ('c' for edible, 'p' for poisonous) to numerical values. \n",
"\n",
    "(1 : c, 0 : p). \n",
"\n",
    "-df['comestibility'] = df['comestibility'].map(Dico): Maps the values in the 'comestibility' column using the defined dictionary, converting comestibility codes to numerical values. \n",
"\n",
    " ### 5.Display DataFrame: \n",
"\n",
    "-df: Displays the modified DataFrame, which now includes numerical values for comestibility."
    

   ]
  },


{
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
"from PIL import Image \n",
"\n",
"file_path = 'champiURL.json' \n",
"df = pd.read_json(file_path) \n",
"df = df.explode('images', ignore_index = True) \n",
"df = df.drop(columns=['info']) \n",
"\n",
"Dico = { \n",
    "'c' : 1, \n",
    "'p' : 0 \n",
"} \n",
"\n",
"df['comestibility'] = df['comestibility'].map(Dico) \n",
"df"
   ]
  },

    {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###This code essentially fetches images from URLs in the DataFrame, converts them to base64 format, and stores the encoded images in the encoded_images list. \n",
"\n",
    " ### 1.Imports: \n",
"\n",
    "-from io import BytesIO: Imports the BytesIO class from the io module, which is used to create in-memory binary streams. \n",
"\n",
"-import base64: Imports the base64 module for encoding and decoding base64 data. \n",
"\n",
"-import requests: Imports the requests module for making HTTP requests. \n",
"\n",
" ### 2.Empty List Initialization: \n",
"\n",
"-encoded_images = []: Initializes an empty list named encoded_images to store base64-encoded images. \n",
"\n",
" ### 3.Loop Through DataFrame and Fetch Images: \n",
"\n",
"-code iterates through each row of the DataFrame (df) using a loop. \n",
"\n",
"-For each iteration: \n",
"\n",
"-It retrieves the image URL from the 'images' column of the DataFrame. \n",
"\n",
"-Makes a GET request to the URL using requests.get(url). \n",
"\n",
"-If successful (status code 200), it opens the image using PIL (Pillow), converts it to base64 using base64.b64encode(), and appends the encoded image to the encoded_images list. \n",
"\n",
" ### 4.Printing Progress: \n",
"\n",
"-if i % 50 == 0:: Prints the progress every 50 iterations, indicating the number of images processed out of the total."
   ]
  },

{
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from io import BytesIO \n",
"import base64 \n",
"import requests \n",
"\n",
"encoded_images = [] \n",
"\n",
"for i in range(len(df)): \n",
    "# Make a GET request to the URL \n",
    "url = df['images'][i] \n",
    "response = requests.get(url) \n",
    "response.raise_for_status()  # Check if the request was successful \n",
"\n",
    "if response.status_code == 200: \n",
        "# Convert the image to base64 \n",
        "image = Image.open(BytesIO(response.content)) \n",
        "img_base64 = base64.b64encode(response.content).decode('utf-8') \n",
        "encoded_images.append(img_base64) \n",
    "else: \n",
        "# If the request was not successful, print an error message \n",
        "print(f'Error: Unable to fetch image from {url}. Status code: {response.status_code}') \n",
"\n",
    "if i%50 == 0: \n",
        "print(f'Image {i}/{len(df)}') \n"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Creates a new column in the DataFrame df called 'encoded_images' and populates it with the contents of the ist encoded_images. \n",
"\n",
"Contains base64-encoded images. \n"
   ]
  },

{
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    
"df['encoded_images'] = encoded_images \n",
"df"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Creation of a csv \n"
   ]
  },

{
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    
"df.to_csv('champipiFinal.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
