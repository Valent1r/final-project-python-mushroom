{
 "cells": [ 
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
{
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install webdriver_manager\n"
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
"import requests \n",
"import re \n",
"import json \n",
"from urllib.parse import urljoin \n",
"\n",
"def scrape_mushroom_list(url): \n",
    "data = requests.get(url).text \n",
    "soup = BeautifulSoup(data, 'html.parser') \n",
    "\n",
    "# Find all links to individual mushroom pages \n",
    "mushroom_links = soup.find_all('a', href=re.compile(r'/show?n=')) \n",
    "mushroom_urls = [urljoin('http://www.mushroom.world', link['href']) for link in mushroom_links] \n",
    "\n",
    "# Retrieve information for each mushroom\n",
    "mushrooms = [scrape_mushroom(link) for link in mushroom_urls] \n",
    "\n",
 "return mushrooms"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },

{
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def scrape_mushroom(url): \n",
    "data = requests.get(url).text \n",
    "soup = BeautifulSoup(data, 'html.parser') \n",
"\n",
    "# Extract specific information for an individual mushroom \n",
    "name_content = soup.find(class_='caption').find('b').contents \n",
    "names = re.sub('[^A-Za-z0-9( ]+', '', name_content[0])).split('(')) \n",
    "names = [n.strip() for n in names] \n",
    "name1 = names[0] \n",
    "name2 = names[1] if len(names) > 1 else '' \n",
"\n",
    "labels = soup.find_all(class_='labelus') \n",
    "labels = [label.contents[0] for label in labels] \n",
"\n",
    "texts = soup.find_all(class_='textus') \n",
    "texts = [text.contents[0] for text in texts] \n",
"\n",
    "# Updated code to remove unwanted lines \n",
    "description = soup.find(class_='longtextus') \n",
    "if description: \n",
        "unwanted_links = description.find_all('a', href=True) \n",
        "for link in unwanted_links: \n",
            "link.extract()  # Remove unwanted links \n",
"\n",
        "description = description.get_text(separator=' ', strip=True) \n",
    "else: \n",
        "description = 'Description not available' \n",
"\n",
    "texts.append(description) \n",
    "assert len(labels) == len(texts) \n",
"\n",
    "images = soup.find(id='mushroom-list').find_all(class_='image') \n",
    "image_urls = [urljoin('http://www.mushroom.world', image.a['href']) for image in images] \n",
"\n",
    "mushroom = dict(name1=name1, name2=name2, images=image_urls, info=dict()) \n",
"\n",
    "for i in range(len(labels)): \n",
        "mushroom['info'][labels[i]] = texts[i] \n",
"\n",
    "return mushroom"

   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },

{
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [

"if __name__ == '__main__': \n",
    "# Link to the list of all mushrooms on mushroom.world \n",
    "all_mushrooms_url = 'http://www.mushroom.world/mushrooms/namelist' \n",
"\n",
    "# Retrieve information on all mushrooms \n",
    "all_mushrooms = scrape_mushroom_list(all_mushrooms_url) \n",
"\n",
    "# Edibility dictionary \n",
    "edibility_dict = { \n",
        "# ... (your edibility dictionary remains unchanged)\n",
          "'Agaricus arvensis': 'c', \n",
  "'Agaricus augustus': 'c', \n",
  "'Agaricus campestris': 'c', \n",
  "'Agaricus sylvicola': 'c', \n",
  "'Agrocybe pediades': 'c', \n",
  "'Agrocybe praecox': 'c', \n",
  "'Albatrellus confluens': 'p', \n",
  "'Albatrellus ovinus': 'c', \n",
  "'Aleuria aurantia': 'p', \n",
  "'Amanita battarrae': 'p',\n",
  "'Amanita bisporigera': 'p',\n",
  "'Amanita cokeri': 'p',\n",
  "'Amanita fulva': 'p',\n",
  "'Amanita jacksonii': 'p',\n",
  "'Amanita muscaria': 'p',\n",
  "'Amanita pantherina': 'p',\n",
  "'Amanita phalloides': 'p',\n",
  "'Amanita porphyria': 'p',\n",
  "'Amanita regalis': 'p',\n",
  "'Amanita rubescens': 'c',\n",
  "'Amanita vaginata': 'p',\n",
  "'Amanita virosa': 'p',\n",
  "'Ampulloclitocybe clavipes': 'p',\n",
  "'Armillaria mellea': 'c',\n",
  "'Auriscalpium vulgare': 'p',\n",
  "'Bankera fuligineoalba': 'p',\n",
  "'Boletus edulis': 'c',\n",
  "'Boletus pinophilus': 'c',\n",
  "'Bondarzewia berkeleyi': 'p',\n",
  "'Bovista nigrescens': 'p',\n",
  "'Bovista plumbea': 'p',\n",
  "'Calocera viscosa': 'p',\n",
  "'Calocybe gambosa': 'p',\n",
  "'Calocybe persicolor': 'p',\n",
  "'Calvatia gigantea': 'p',\n",
  "'Cantharellula umbonata': 'p',\n",
  "'Cantharellus cibarius': 'c',\n",
  "'Chalciporus piperatus': 'p',\n",
  "'Chlorophyllum molybdites': 'p',\n",
  "'Chlorophyllum rhacodes': 'p',\n",
  "'Chroogomphus britannicus': 'p',\n",
  "'Clathrus ruber': 'p',\n",
  "'Conocybe apala': 'p',\n",
  "'Coprinellus disseminatus': 'p',\n",
  "'Coprinellus xanthothrix': 'p',\n",
  "'Coprinopsis atramentaria': 'p',\n",
  "'Coprinopsis variegata': 'p',\n",
  "'Conocybe apala': 'p',\n",
  "'Coprinopsis variegata': 'p',\n",
  "'Coprinus comatus': 'p',\n",
  "'Coprinus plicatilis': 'p',\n",
  "'Cortinarius alboviolaceus': 'p',\n",
  "'Cortinarius armillatus': 'p',\n",
  "'Cortinarius camphoratus': 'p',\n",
  "'Cortinarius caperatus': 'p',\n",
  "'Cortinarius collinitus': 'p',\n",
  "'Cortinarius croceus': 'p',\n",
  "'Cortinarius laniger': 'p',\n",
  "'Cortinarius malicorius': 'p',\n",
  "'Cortinarius mucosus': 'p',\n",
  "'Cortinarius orellanus': 'p',\n",
  "'Cortinarius rubellus': 'p',\n",
  "'Cortinarius semisanguineus': 'p',\n",
  "'Cortinarius traganus': 'p',\n",
  "'Cortinarius violaceus': 'p',\n",
  "'Craterellus tubaeformis': 'c',\n",
  "'Cystoderma amianthinum': 'p',\n",
  "'Cystodermella cinnabarina': 'p',\n",
  "'Entoloma sericeum': 'p',\n",
  "'Entoloma vernum': 'p',\n",
  "'Galerina marginata': 'p',\n",
  "'Geastrum rufescens': 'p',\n",
  "'Gomphidius glutinosus': 'p',\n",
  "'Gymnopilus picreus': 'p',\n",
  "'Gymnopus peronatus': 'p',\n",
  "'Gyromitra esculenta': 'p',\n",
  "'Gyromitra esculenta': 'p',\n",
  "'Gyromitra infula': 'p',\n",
  "'Hebeloma crustuliniforme': 'p',\n",
  "'Hebeloma mesophaeum': 'p',\n",
  "'Helvella elastica': 'p',\n",
  "'Hericium americanum': 'p',\n",
  "'Hericium cirrhatum': 'p',\n",
  "'Hericium erinaceus': 'p',\n",
  "'Hortiboletus rubellus': 'p',\n",
  "'Hydnum repandum': 'p',\n",
  "'Hydnum rufescens': 'p',\n",
  "'Hygrophoropsis aurantiaca': 'p',\n",
  "'Hygrophorus camarophyllus': 'p',\n",
  "'Hygrophorus hypothejus': 'p',\n",
  "'Hygrophorus hypothejus': 'p',\n",
  "'Hygrophorus pustulatus': 'c',\n",
  "'Hypholoma capnoides': 'p',\n",
  "'Hypholoma fasciculare': 'p',\n",
  "'Hypholoma lateritium': 'p',\n",
  "'Hypholoma lateritium': 'p',\n",
  "'Hypholoma marginatum': 'p',\n",
  "'Imleria badia': 'p',\n",
  "'Inocybe lacera': 'p',\n",
  "'Kuehneromyces lignicola': 'p',\n",
  "'Kuehneromyces mutabilis': 'p',\n",
  "'Laccaria laccata': 'p',\n",
  "'Lacrymaria lacrymabunda': 'p',\n",
  "'Lactarius camphoratus': 'p',\n",
  "'Lactarius deliciosus': 'c',\n",
  "'Lactarius deterrimus': 'p',\n",
  "'Lactarius helvus': 'p',\n",
  "'Lactarius indigo': 'p',\n",
  "'Lactarius lignyotus': 'p',\n",
  "'Lactarius mammosus': 'p',\n",
  "'Lactarius rufus': 'p',\n",
  "'Lactarius tabidus': 'p',\n",
  "'Lactarius torminosus': 'p',\n",
  "'Lactarius trivialis': 'p',\n",
  "'Lactarius turpis': 'p',\n",
  "'Lactarius volemus': 'p',\n",
  "'Lactifluus piperatus': 'p',\n",
  "'Laetiporus sulphureus': 'p',\n",
  "'Leccinum aurantiacum': 'p',\n",
  "'Leccinum scabrum': 'p',\n",
  "'Leccinum versipelle': 'p',\n",
  "'Lepiota clypeolaria': 'p',\n",
  "'Leucocoprinus birnbaumii': 'p',\n",
  "'Leucocybe connata': 'p',\n",
  "'Lycoperdon excipuliforme': 'p',\n",
  "'Lycoperdon nigrescens': 'p',\n",
  "'Lycoperdon perlatum': 'p',\n",
  "'Lycoperdon pratense': 'p',\n",
  "'Lycoperdon pyriforme': 'p',\n",
  "'Macrolepiota procera': 'p',\n",
  "'Marasmiellus perforans': 'p',\n",
  "'Marasmius oreades': 'p',\n",
  "'Melanoleuca cognata': 'p',\n",
  "'Morchella elata': 'p',\n",
  "'Morchella esculenta': 'p',\n",
  "'Mycena epipterygia': 'p',\n",
  "'Mycena galericulata': 'p',\n",
  "'Mycena laevigata': 'p',\n",
  "'Mycena pura': 'p',\n",
  "'Omphalotus illudens': 'p',\n",
  "'Omphalotus olearius': 'p',\n",
  "'Otidea onotica': 'p',\n",
  "'Panaeolus foenisecii': 'p',\n",
  "'Paxillus involutus': 'p',\n",
  "'Peziza badia': 'p',\n",
  "'Phallus impudicus': 'p',\n",
  "'Phallus rubicundus': 'p',\n",
  "'Pholiota alnicola': 'p',\n",
  "'Pholiota aurivella': 'p',\n",
  "'Pholiota limonella': 'p',\n",
  "'Pholiota squarrosa': 'p',\n",
  "'Pleurotus citrinopileatus': 'p',\n",
  "'Pleurotus ostreatus': 'c',\n",
  "'Pleurotus pulmonarius': 'c',\n",
  "'Polyporus ciliatus': 'p',\n",
  "'Polyporus squamosus': 'p',\n",
  "'Psathyrella candolleana': 'c',\n",
  "'Psathyrella microrrhiza': 'p',\n",
  "'Psathyrella sp.': 'p',\n",
  "'Psilocybe semilanceata': 'p',\n",
  "'Rickenella swartzii': 'c',\n",
  "'Rubroboletus satanas': 'p',\n",
  "'Russula acrifolia': 'p', \n",
  "'Russula adusta': 'p', \n",
  "'Russula aeruginea': 'p',\n",
  "'Russula claroflava': 'p',\n",
  "'Russula paludosa': 'c',\n",
  "'Russula velenovskyi': 'p',\n",
  "'Russula vesca': 'c',\n",
  "'Russula vinosa': 'c',\n",
  "'Russula xerampelina': 'c',\n",
  "'Sarcodon squamosus': 'p',\n",
  "'Strobilomyces strobilaceus': 'p',\n",
  "'Strobilurus esculentus': 'c',\n",
  "'Strobilurus stephanocystis': 'p',\n",
  "'Stropharia hornemannii': 'p',\n",
  "'Suillus americanus': 'c', \n",
  "'Suillus bovinus': 'c', \n",
  "'Suillus grevillei': 'p', \n",
  "'Suillus luteus': 'c', \n",
  "'Suillus variegatus': 'p', \n",
  "'Tapinella atrotomentosa': 'c', \n",
  "'Tapinella panuoides': 'p', \n",
  "'Tricholoma aestuans': 'p', \n",
  "'Tricholoma equestre': 'c', \n",
  "'Tricholoma focale': 'p', \n",
  "'Tricholoma saponaceum': 'p', \n",
  "'Tricholoma sejunctum': 'p', \n",
  "'Tricholoma stiparophyllum': 'p', \n",
  "'Tricholomopsis decora': 'p', \n",
  "'Tricholomopsis rutilans': 'p', \n",
  "'Turbinellus floccosus': 'p', \n",
  "'Tylopilus felleus': 'p', \n",
  "'Xerocomellus chrysenteron': 'c', \n",
  "'Xerocomus subtomentosus': 'c', \n",
  "'Xeromphalina campanella': 'p', \n",
  "'Tricholomopsis decora': 'p', \n",
  "'Clitocybe gibba': 'c', \n",
  "'Clitocybe nuda': 'c', \n",
  "'Clitopilus prunulus': 'c', \n",
  "'Collybia dryophila': 'c', \n",
  "'Coltricia perennis': 'p', \n",
  "'Conocybe apalas': 'p', \n",
  "'Marasmius rotula': 'p', \n",
  "'Tricholomataceae': 'c', \n",
  "'Ramaria lutea': 'p', \n",
  "'Rhizina undulata': 'p', \n",
  "'Russula decolorans': 'c', \n",
  "'Russula emetica': 'p', \n",
  "'Russula mustelina': 'c', \n",
  "'Clitocybe nebularis': 'p', \n",
    "}\n",
 "\n",
    "# Add edibility to final output \n",
    "for mushroom in all_mushrooms: \n",
        "name = mushroom['name1'] \n",
        "if name in edibility_dict: \n",
            "mushroom['comestibility'] = edibility_dict[name] \n",
        "else: \n",
            "mushroom['comestibility'] = 'Information not available' \n",
        "# Delete edibility information from web page \n",
        "if 'Edibility' in mushroom['info']: \n",
            "del mushroom['info']['Edibility'] \n",
 "\n",
    "# Display information (or save to file, etc.) \n",
    "print(json.dumps(all_mushrooms, indent=2))"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },



{
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install Pillow"
   ]
  },


{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code reads a JSON file containing mushroom data into a pandas DataFrame, processes the DataFrame by exploding the 'images' column, dropping the 'info' column, and then mapping the 'comestibility' values to numeric values (1 for 'c' and 0 for 'p'). It further cleans the DataFrame by dropping rows with missing values and resetting the index, ultimately converting the 'comestibility' column to integer type. The resulting DataFrame is displayed."
   ]
  },
    
{
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
"\n",
"file_path = 'champiURL.json' \n",
"df = pd.read_json(file_path) \n",
"df = df.explode('images', ignore_index = True) \n",
"df = df.drop(columns=['info']) \n",
"\n",
"mapping = { \n",
"    'c' : 1, \n",
"    'p' : 0 \n",
"} \n",
"\n",
"df['comestibility'] = df['comestibility'].map(mapping) \n",
"df = df.dropna().reset_index() \n",
"df['comestibility'] = df['comestibility'].astype(int) \n",
"df \n"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script utilizes the Python Imaging Library (PIL) to download images from URLs stored in a DataFrame. It first checks if the 'images' directory exists and creates it if not. Then, for each row in the DataFrame, it makes a GET request to the image URL, retrieves the image data, resizes it to 96x96 pixels, and saves it as a PNG file in the 'images' directory. The script also includes error handling to print messages in case of unsuccessful requests and displays progress messages for every 50 images processed."
   ]
  },

{
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image \n",
"from io import BytesIO \n",
"import numpy as np \n",
"import requests \n",
"import os \n",
"\n",
"if not os.path.exists('images'): \n",
       "# Create the directory if it doesn't exist \n",
        "os.makedirs('images') \n",
"\n",
"for i in range(len(df)): \n",
    "# Make a GET request to the URL \n",
    "url = df['images'][i] \n",
    "response = requests.get(url) \n",
    "response.raise_for_status()  # Check if the request was successful \n",
"\n",
    "if response.status_code == 200: \n",
        "# Convert the image to base64 \n",
        "image = Image.open(BytesIO(response.content)) \n",
        "image = image.resize((96, 96)) \n",
        "image.save(f'images/{i+1}.png') \n",
    "else: \n",
        "# If the request was not successful, print an error message \n",
        "print(f'Error: Unable to fetch image from {url}. Status code: {response.status_code}') \n",
"\n",
    "if i%50 == 0: \n",
        "print(f'Image {i}/{len(df)}')"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script initializes an empty list to store images and then loops through the rows of the DataFrame 'df'. For each row, it reads the corresponding image from the 'images' folder, converts it to a NumPy array, resizes it to the specified dimensions (96x96 pixels), and appends the array to the list. Finally, the list of image arrays is converted into a NumPy array, and the shape of the resulting array is printed. This script essentially reads and processes images from the 'images' folder, preparing them for further analysis."
   ]
  },

{
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [

"img_size = 96 \n",    
"# Initialize an empty list to store images \n",
"images_list = [] \n",
"\n",
"# Loop through the rows of the DataFrame 'df' \n",
"for i in range(len(df)): \n",
    "# Read each image from the 'images' folder and convert it to a NumPy array \n",
    "images_list.append(np.array(Image.open(f'images/{i+1}.png').resize((img_size, img_size)))) \n",
"\n",
"# Convert the list of image arrays to a NumPy array \n",
"images_list = np.array(images_list) \n",
"\n",
"# Print the shape of the resulting NumPy array \n",
"print(images_list.shape)"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script imports necessary libraries from TensorFlow and other packages, defines a function named let_me_see for visualizing training and validation history using matplotlib, and checks if the script is executed as the main module to create a 'models' folder for saving trained models if it doesn't exist. The main purpose of the script seems to be setting up the environment for building and training neural network models using TensorFlow for a classification task. The let_me_see function is designed to visualize the training and validation accuracy as well as the loss over epochs."
   ]
  },

{
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    
"# Importing necessary libraries from TensorFlow and other packages \n",
"from tensorflow import keras \n",
"import tensorflow as tf \n",
"from tensorflow.keras.models import Sequential \n",
"from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom \n",
"from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D \n",
"from sklearn.utils import shuffle \n",
"import matplotlib.pyplot as plt \n",
"import numpy as np \n",
"import os \n",
"\n",
"# Function to visualize training and validation history \n",
"def let_me_see(history): \n",
    "# Create a figure with two subplots for accuracy and loss \n",
    "plt.figure(figsize=(8, 4)) \n",
    "plt.subplot(1, 2, 1) \n",
"\n",
    "# Plot training and validation accuracy \n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy') \n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy') \n",
    "plt.xlabel('Epochs') \n",
    "plt.ylabel('Accuracy') \n",
    "plt.legend() \n",
"\n",
    "plt.subplot(1, 2, 2) \n",
"\n",    
    "# Plot training and validation loss \n",
    "plt.plot(history.history['loss'], label='Training Loss') \n",
    "plt.plot(history.history['val_loss'], label='Validation Loss') \n",
    "plt.xlabel('Epochs') \n",
    "plt.ylabel('Loss') \n",
    "plt.legend() \n",
"\n",
    "# Adjust layout for better visualization \n",
    "plt.tight_layout() \n",
    "plt.show() \n",
"\n",
"# Check if the script is executed as the main module \n",
"if __name__ == '__main__': \n",
    "# Create a folder named 'models' to save trained models if it doesn't exist \n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, if the script is executed as the main module, it loads the Mushroom dataset (images_list and comestibility labels) and performs data preparation steps. It normalizes the input data by dividing it by 255.0, shuffles the dataset using the shuffle function from scikit-learn, and comments about the expected shapes of X (input images) and y (labels) after these transformations. The labels are not one-hot encoded in this version of the script, and the shape of y is mentioned as (1027, 2)."
   ]
  },

{
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    
"if __name__ == '__main__': \n",
    "# Load the MNIST dataset and split it into training and testing sets \n",
    "X, y = images_list, np.array(df['comestibility']) \n",
"\n",
    "# Perform data normalization \n",
    "X = X / 255.0 \n",
"\n",
    "# Convert the labels to one-hot encoded vectors \n",
   " #y = keras.utils.to_categorical(y) \n",
    "X, y = shuffle(X, y) \n",
"\n",
    "# X: (N, h, w, c) = (1027, 64, 64, 3) \n",
    "# y: (N, 2) = (1027, 2)"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the script includes a conditional check to determine if it is the main module. If true, it proceeds to define two lists, one containing human-readable class names ('Toxic', 'Comestible'), and the other containing corresponding integer labels (1, 0). These lists are likely used for classification tasks, providing a mapping between class names and their numerical representations."
   ]
  },


{
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    
"# Check if the script is executed as the main module \n",
"if __name__ == '__main__': \n",
    "# Define classes for classification \n",
    "classes = ['Toxic', 'Comestible'] \n",
    "classes_int = [1, 0]"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },


{
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    
"print(y.shape)"
   ]
  },


{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, if the script is executed as the main module, it visualizes a set of images from the training data (X) along with their corresponding class labels (y). The script creates a 5x5 grid of subplots, displaying images with their associated class names. The images are plotted using matplotlib, and the class names are included as titles for each subplot."
   ]
  },

{
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    
"if __name__ == '__main__': \n",
   "# visualize the picture in x_train \n",
    "plt.figure(figsize=(10, 10)) \n",
    "for i in range(25): \n",
        "plt.subplot(5, 5, i+1) \n",
        "plt.imshow(X[i]) \n",
       "plt.xticks([]) \n",
        "plt.yticks([]) \n",
        "plt.title(f'Class : {classes[y[i]]}')"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##This code block sets up a data augmentation pipeline using TensorFlow and Keras, applying horizontal flipping, rotation, and zoom to enhance the diversity of the training data."
   ]
  },

{
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    
"data_augmentation = keras.Sequential( \n",
  "[ \n",
    "RandomFlip('horizontal',input_shape=(img_size, img_size, 3)), \n",
    "RandomRotation(0.3), \n",
    "RandomZoom(0.3), \n",
  "] \n",
")"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function defines a convolutional neural network (CNN) model for image classification. The model includes data augmentation, a convolutional layer with max-pooling and dropout, a flattening layer, a dense layer with ReLU activation and dropout, and a final dense layer with sigmoid activation for binary classification. The function takes the input image shape as a parameter and returns the constructed model."
   ]
  },

{
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    
"def myModel(img_shape): \n",
    "# Create a sequential model \n",
    "model = Sequential() \n",
"\n",
    "model.add(data_augmentation) \n",
"\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(img_size, img_size, 3))) \n",
    "model.add(MaxPooling2D((2, 2))) \n",
    "model.add(Dropout(0.2)) \n",
"\n",
    "model.add(Flatten()) \n",
    "model.add(Dense((64), activation='relu')) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
"\n",
    "return model"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, if the script is run as the main module, a convolutional neural network (CNN) model is created, compiled with Adam optimizer and binary crossentropy loss, and then trained on the provided data for 5 epochs. The training history is stored in the 'history' variable."
   ]
  },

{
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    
"if __name__ == '__main__': \n",
    "# Create the model \n",
    "model = myModel(img_shape=(img_size, img_size, 3)) \n",
"\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
"\n",
    "# Train the model \n",
    "history = model.fit(X, y, epochs=5, batch_size=128, validation_split=0.2) #80% accurary for the classification = good"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Here we can use this code to see what the model looks like post training."
   ]
  },


{
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    
"if __name__ == '__main__': \n",
    "let_me_see(history)"

   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##This permits us to see the model prediction of each image of our dataset"
   ]
  },

{
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    
"print(model.predict(X))"
   ]
  },

{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##This is the final product of our project : The prediction of any image."
   ]
  },

{
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    
"def predict_mushroom(img): \n",
    "img = img.convert('RGB') \n",
    "img_array = np.array(img) / 255.0 \n",
    "img_array = np.expand_dims(img_array, 0) \n",
    "predict = model.predict(img_array) \n",
    "plt.imshow(img) \n",
    "plt.xticks([]) \n",
    "plt.yticks([]) \n",
    "plt.title(classes[predict.argmax()] + ' by ' + str(round((classes_int[round(predict[0][0])] - predict[0][0])*100, 1)) + '%') \n",
    "plt.show() \n",
"\n",
"img = Image.open(f'images/754.png').resize((img_size, img_size)) \n",
"predict_mushroom(img)"
   ]
  },
{
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  }

 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
